RAGAS(Retrieval Augmented Generation Assessment)는 Retrieval Augmented Generation(RAG) 파이프라인의 성능을 자동으로 평가하기 위한 오픈소스 프레임워크입니다. RAG 시스템은 검색(retrieval) 모듈과 대규모 언어 모델(LLM) 기반 생성 모듈로 구성되어 있습니다. RAGAS는 이러한 RAG 아키텍처의 다양한 측면을 평가할 수 있는 메트릭 스위트를 제공합니다

## RAGAS의 주요 특징

1. 참조 없는 평가(Reference-free evaluation): 인간이 작성한 정답 데이터 없이도 평가가 가능합니다

2. 컴포넌트별 평가: 검색 모듈과 생성 모듈을 개별적으로 평가할 수 있습니다

3. 종합적인 평가: RAG 파이프라인의 전체적인 성능도 평가할 수 있습니다

4. LLM 기반 메트릭: 일부 메트릭은 LLM을 활용하여 더 정확한 평가를 수행합니다

## RAGAS 평가 데이터 형식

RAGAS는 다음과 같은 형식의 데이터셋을 가짐

- `question`: 사용자 쿼리 (RAG의 입력)
- `answer`: RAG 파이프라인이 생성한 답변
- `contexts`: 지식 베이스에서 검색된 컨텍스트
- `ground_truths`: 질문에 대한 정답 (선택적, Context Recall 메트릭에만 필요)

## RAGAS 메트릭

RAGAS는 크게 검색 단계와 생성 단계를 평가하는 메트릭을 제공합니다

네, RAGAS의 평가 지표들에 대해 더 자세히 설명해 드리겠습니다.

## 검색 단계 메트릭 상세 설명

### 1. Context Precision (컨텍스트 정밀도)

컨텍스트 정밀도는 검색된 문서들이 얼마나 질문과 관련이 있는지를 측정합니다.

- **계산 방법**: LLM을 사용하여 각 검색된 문서와 질문 사이의 관련성을 평가합니다.
- **점수 범위**: 0에서 1 사이, 1에 가까울수록 더 정확한 검색을 의미합니다.
- **중요성**: 높은 컨텍스트 정밀도는 LLM이 관련 없는 정보로 인해 혼란을 겪지 않도록 합니다.

### 2. Context Relevancy (컨텍스트 관련성)

컨텍스트 관련성은 검색된 문서들이 질문에 얼마나 유용한 정보를 포함하고 있는지를 평가합니다.

- **계산 방법**: 검색된 각 문서에 대해 LLM을 사용하여 질문에 대한 답변을 생성한 후, 이 답변과 실제 생성된 답변 사이의 유사도를 측정합니다.
- **점수 범위**: 0에서 1 사이, 1에 가까울수록 더 관련성 높은 컨텍스트를 의미합니다.
- **중요성**: 높은 컨텍스트 관련성은 LLM이 질문에 더 정확하게 답변할 수 있도록 합니다.

### 3. Context Recall (컨텍스트 재현율)

컨텍스트 재현율은 정답에 필요한 모든 정보가 검색된 문서들에 포함되어 있는지를 평가합니다.

- **계산 방법**: 정답(ground truth)의 각 문장이 검색된 문서들에서 발견되는지를 확인합니다.
- **점수 범위**: 0에서 1 사이, 1에 가까울수록 더 완전한 정보 검색을 의미합니다.
- **중요성**: 높은 컨텍스트 재현율은 LLM이 답변에 필요한 모든 정보를 가지고 있음을 보장합니다.

### 4. Context Entities Recall (컨텍스트 엔티티 재현율)

컨텍스트 엔티티 재현율은 질문과 정답에 포함된 중요 엔티티들이 검색된 문서들에 얼마나 포함되어 있는지를 측정합니다.

- **계산 방법**: 질문과 정답에서 추출한 엔티티들이 검색된 문서들에 존재하는지 확인합니다.
- **점수 범위**: 0에서 1 사이, 1에 가까울수록 더 많은 관련 엔티티가 포함되어 있음을 의미합니다.
- **중요성**: 높은 엔티티 재현율은 LLM이 질문의 핵심 요소들에 대한 정보를 가지고 있음을 보장합니다.

## 생성 단계 메트릭 상세 설명

### 1. Faithfulness (충실도)

충실도는 생성된 답변이 검색된 문서들의 내용에 얼마나 충실한지를 평가합니다.

- **계산 방법**: LLM을 사용하여 생성된 답변의 각 문장이 검색된 문서들에서 지지되는지 확인합니다.
- **점수 범위**: 0에서 1 사이, 1에 가까울수록 더 충실한 답변을 의미합니다.
- **중요성**: 높은 충실도는 LLM이 허위 정보를 생성하지 않았음을 보장합니다.

### 2. Answer Relevancy (답변 관련성)

답변 관련성은 생성된 답변이 원래 질문에 얼마나 적절한지를 평가합니다.

- **계산 방법**: 
  1. 생성된 답변을 기반으로 가상의 질문들을 만듭니다.
  2. 이 가상 질문들과 원래 질문 사이의 의미적 유사도를 계산합니다.
- **점수 범위**: 0에서 1 사이, 1에 가까울수록 더 관련성 높은 답변을 의미합니다.
- **중요성**: 높은 답변 관련성은 LLM이 질문의 의도를 정확히 파악하고 답변했음을 나타냅니다.

### 3. Answer Correctness (답변 정확성)

답변 정확성은 생성된 답변이 사실적으로 얼마나 정확한지를 평가합니다.

- **계산 방법**: LLM을 사용하여 생성된 답변의 각 문장이 검색된 문서들의 내용과 일치하는지 확인합니다.
- **점수 범위**: 0에서 1 사이, 1에 가까울수록 더 정확한 답변을 의미합니다.
- **중요성**: 높은 답변 정확성은 LLM이 사실에 기반한 정확한 정보를 제공했음을 나타냅니다.

### 4. Answer Similarity (답변 유사도)

답변 유사도는 생성된 답변이 참조 답변(정답)과 얼마나 유사한지를 측정합니다.

- **계산 방법**: 생성된 답변과 참조 답변 사이의 의미적 유사도를 계산합니다. 주로 BERT나 RoBERTa 같은 언어 모델을 사용하여 계산합니다.
- **점수 범위**: 0에서 1 사이, 1에 가까울수록 참조 답변과 더 유사한 답변을 의미합니다.
- **중요성**: 높은 답변 유사도는 LLM이 정답에 가까운 답변을 생성했음을 나타냅니다.

## 메트릭 활용 전략

1. **종합적 평가**: 모든 메트릭을 함께 고려하여 RAG 시스템의 전반적인 성능을 평가합니다.

2. **단계별 최적화**: 검색 단계와 생성 단계의 메트릭을 분리하여 각 단계를 독립적으로 최적화할 수 있습니다.

3. **지속적 모니터링**: 시간에 따른 메트릭 변화를 추적하여 시스템의 성능 변화를 관찰합니다.

4. **A/B 테스팅**: 다른 검색 알고리즘이나 LLM 모델을 사용했을 때의 메트릭 변화를 비교합니다.

5. **임계값 설정**: 각 메트릭에 대한 최소 허용 임계값을 설정하여 품질 관리를 수행합니다.

이러한 상세한 메트릭들을 활용하면 RAG 시스템의 각 구성 요소를 정밀하게 평가하고 개선할 수 있습니다. 이는 결과적으로 더 정확하고 신뢰할 수 있는 질문-답변 시스템을 구축하는 데 큰 도움이 될 것입니다.

## RAGAS 사용 방법

1. RAGAS 설치:
   ```
   pip install ragas
   ```

2. 필요한 메트릭 임포트:
   ```python
   from ragas.metrics import (
       context_precision,
       context_relevancy,
       faithfulness,
       answer_relevancy
   )
   ```

3. 데이터셋 준비 및 평가 실행:
   ```python
   from ragas import evaluate
   
   result = evaluate(
       dataset=dataset,
       metrics=[
           context_precision,
           context_relevancy,
           faithfulness,
           answer_relevancy
       ]
   )
   ```

4. 결과 분석:
   ```python
   df = result.to_pandas()
   print(df)
   ```

